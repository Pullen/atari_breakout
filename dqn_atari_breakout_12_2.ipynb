{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of dqn_atari_breakout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pullen/atari_breakout/blob/main/dqn_atari_breakout_12_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "Nds92rPvktVT",
        "outputId": "bce3f3f3-b36b-4e67-aecf-3571277d4b0f"
      },
      "source": [
        "pip install h5py==2.10.0 ###  need <3.0 to have current code work for saving and loading of weights"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m6Qk5NRvziD"
      },
      "source": [
        "# Deep Q-Network implementation\n",
        "\n",
        "This notebook implements a DQN - an approximate q-learning algorithm with experience replay and target networks. Trains the algorithm on openAI's gym, to breakout Atari game, and monitors its games by exporting videos.\n",
        "\n",
        "The code was developed as part of [Practical Reinforcement Learning](https://https://www.coursera.org/learn/practical-rl) course on Coursera.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seT-YHg5vziF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3c472c-3a79-4b6f-dfd1-5dd61054f45b"
      },
      "source": [
        "#XVFB will be launched if you run on a server\n",
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    %tensorflow_version 1.x\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "bash: ../xvfb: No such file or directory\n",
            "env: DISPLAY=:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C5cmoBmvziM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b8d39c-1d14-470a-c16b-5eb3b4f7ab89"
      },
      "source": [
        "#Make necessary imports\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')\n",
        "!pip install unrar\n",
        "!unrar x Roms.rar\n",
        "!mkdir rars\n",
        "!mv HC\\ ROMS.zip   rars\n",
        "!mv ROMS.zip  rars\n",
        "!python -m atari_py.import_roms rars"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unrar in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Roms.rar\n",
            "\n",
            "Extracting  HC ROMS.zip                                                  \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  ROMS.zip                                                     \b\b\b\b 74%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "mkdir: cannot create directory ‘rars’: File exists\n",
            "copying adventure.bin from ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying air_raid.bin from ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying alien.bin from ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying amidar.bin from ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying assault.bin from ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying asterix.bin from ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n",
            "copying asteroids.bin from ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying atlantis.bin from ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying bank_heist.bin from ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying battle_zone.bin from ROMS/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying beam_rider.bin from ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying berzerk.bin from ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying bowling.bin from ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying boxing.bin from ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying breakout.bin from ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying carnival.bin from ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying centipede.bin from ROMS/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying chopper_command.bin from ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying crazy_climber.bin from ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying defender.bin from ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying demon_attack.bin from ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying donkey_kong.bin from ROMS/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying double_dunk.bin from ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying elevator_action.bin from ROMS/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying enduro.bin from ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying fishing_derby.bin from ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying freeway.bin from ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying frogger.bin from ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying frostbite.bin from ROMS/Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying galaxian.bin from ROMS/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying gopher.bin from ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying gravitar.bin from ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying hero.bin from ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying ice_hockey.bin from ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying jamesbond.bin from ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying journey_escape.bin from ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying kaboom.bin from ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying kangaroo.bin from ROMS/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying keystone_kapers.bin from ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying king_kong.bin from ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying koolaid.bin from ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying krull.bin from ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying kung_fu_master.bin from ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying laser_gates.bin from ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying lost_luggage.bin from ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying montezuma_revenge.bin from ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying mr_do.bin from ROMS/Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying ms_pacman.bin from ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying name_this_game.bin from ROMS/Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying pacman.bin from ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying phoenix.bin from ROMS/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying video_pinball.bin from ROMS/Pinball (AKA Video Pinball) (Zellers).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying pitfall.bin from ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying pooyan.bin from ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying private_eye.bin from ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying qbert.bin from ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying riverraid.bin from ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying road_runner.bin from patched version of ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying robotank.bin from ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying seaquest.bin from ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying sir_lancelot.bin from ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying skiing.bin from ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying solaris.bin from ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying space_invaders.bin from ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying star_gunner.bin from ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying surround.bin from ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying tennis.bin from ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying time_pilot.bin from ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying trondead.bin from ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying tutankham.bin from ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying up_n_down.bin from ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying venture.bin from ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying pong.bin from ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying wizard_of_wor.bin from ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying yars_revenge.bin from ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying zaxxon.bin from ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAfMgPNBvziQ"
      },
      "source": [
        "### Processing game image \n",
        "\n",
        "Raw atari images are large, 210x160x3 by default. However, we don't need that level of detail in order to learn them.\n",
        "\n",
        "We can thus save a lot of time by preprocessing game image, including\n",
        "* Resizing to a smaller shape, 64 x 64\n",
        "* Converting to grayscale\n",
        "* Cropping irrelevant image parts (top & bottom)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzuRB5OEvziV"
      },
      "source": [
        "from gym.core import ObservationWrapper\n",
        "from gym.spaces import Box\n",
        "\n",
        "# from scipy.misc import imresize\n",
        "import cv2\n",
        "\n",
        "class PreprocessAtari(ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"A gym wrapper that crops, scales image into the desired shapes and optionally grayscales it.\"\"\"\n",
        "        ObservationWrapper.__init__(self,env)\n",
        "        \n",
        "        self.img_size = (84, 84)\n",
        "        self.observation_space = Box(0.0, 1.0, (self.img_size[0], self.img_size[1], 1))\n",
        "\n",
        "    def observation(self, img):\n",
        "        \"\"\"what happens to each observation\"\"\"\n",
        "        \n",
        "        # crop image (top and bottom, top from 34, bottom remove last 16)\n",
        "        img = img[34:-16, :, :]\n",
        "        \n",
        "        # resize image\n",
        "        img = cv2.resize(img, self.img_size)\n",
        "        \n",
        "        img = img.mean(-1,keepdims=True)\n",
        "        \n",
        "        img = img.astype('float32') / 255.\n",
        "              \n",
        "        return img\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsb99gIIvzid"
      },
      "source": [
        "### Frame buffer\n",
        "\n",
        "Our agent can only process one observation at a time, so we gotta make sure it contains enough information to find optimal actions. For instance, agent has to react to moving objects so he must be able to measure object's velocity.\n",
        "\n",
        "To do so, we introduce a buffer that stores 4 last images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IA-czvUwbOn"
      },
      "source": [
        "from gym.spaces.box import Box\n",
        "from gym.core import Wrapper\n",
        "class FrameBuffer(Wrapper):\n",
        "    def __init__(self, env, n_frames=4, dim_order='tensorflow'):\n",
        "        \"\"\"A gym wrapper that reshapes, crops and scales image into the desired shapes\"\"\"\n",
        "        super(FrameBuffer, self).__init__(env)\n",
        "        self.dim_order = dim_order\n",
        "        if dim_order == 'tensorflow':\n",
        "            height, width, n_channels = env.observation_space.shape\n",
        "            \"\"\"Multiply channels dimension by number of frames\"\"\"\n",
        "            obs_shape = [height, width, n_channels * n_frames] \n",
        "        else:\n",
        "            raise ValueError('dim_order should be \"tensorflow\" or \"pytorch\", got {}'.format(dim_order))\n",
        "        self.observation_space = Box(0.0, 1.0, obs_shape)\n",
        "        self.framebuffer = np.zeros(obs_shape, 'float32')\n",
        "        \n",
        "    def reset(self):\n",
        "        \"\"\"resets breakout, returns initial frames\"\"\"\n",
        "        self.framebuffer = np.zeros_like(self.framebuffer)\n",
        "        self.update_buffer(self.env.reset())\n",
        "        return self.framebuffer\n",
        "    \n",
        "    def step(self, action):\n",
        "        \"\"\"plays breakout for 1 step, returns frame buffer\"\"\"\n",
        "        new_img, reward, done, info = self.env.step(action)\n",
        "        self.update_buffer(new_img)\n",
        "        return self.framebuffer, reward, done, info\n",
        "    \n",
        "    def update_buffer(self, img):\n",
        "        if self.dim_order == 'tensorflow':\n",
        "            offset = self.env.observation_space.shape[-1]\n",
        "            axis = -1\n",
        "            cropped_framebuffer = self.framebuffer[:,:,:-offset]\n",
        "        self.framebuffer = np.concatenate([img, cropped_framebuffer], axis = axis)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fVuXynjSvzie"
      },
      "source": [
        "\n",
        "def make_env():\n",
        "    env = gym.make(\"BreakoutDeterministic-v4\")\n",
        "    env = PreprocessAtari(env)\n",
        "    env = FrameBuffer(env, n_frames=4, dim_order='tensorflow')\n",
        "    return env\n",
        "\n",
        "#Instatntiate gym Atari-Breakout environment\n",
        "env = make_env()\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTgKMqCQCTgc",
        "outputId": "2c7f4c5e-4e89-4747-c548-056b3d0ebb10"
      },
      "source": [
        "state_dim"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 84, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgKEPcj2vzii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "c918ed65-bfbe-423a-d959-9498860a028d"
      },
      "source": [
        "# review Atari image, and actual observation of the Agent after processing\n",
        "for _ in range(50):\n",
        "    obs, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "\n",
        "plt.title(\"Game image\")\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "plt.show()\n",
        "plt.title(\"Agent observation (4 frames left to right)\")\n",
        "plt.imshow(obs.transpose([0,2,1]).reshape([state_dim[0],-1]));"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu8jQfGsvzim"
      },
      "source": [
        "### Building a network\n",
        "\n",
        "We now need to build a neural network that can map images to state q-values. This network will be called on every agent's step so it better not be resnet-152 unless we have an array of GPUs. Instead, we can use strided convolutions with a small number of features to save time and memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sPSFBCyvzio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cff4802-da90-46d8-e02e-6a7e81858f84"
      },
      "source": [
        "#Import TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Conv2D, Dense, Flatten, InputLayer\n",
        "\n",
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbNLkHuDvziq"
      },
      "source": [
        "from keras.layers import Conv2D, Dense, Flatten\n",
        "class DQNAgent:\n",
        "    def __init__(self, name, state_shape, n_actions, epsilon=0, reuse=False):\n",
        "        \"\"\"A simple DQN agent\"\"\"\n",
        "        with tf.variable_scope(name, reuse=reuse):\n",
        "            \n",
        "            self.network = keras.models.Sequential()\n",
        "    \n",
        "            # Keras ignores the first dimension in the input_shape, which is the batch size. \n",
        "            # So just use state_shape for the input shape\n",
        "            self.network.add(Conv2D(32, (8, 8), strides=4, activation='relu',use_bias=False, input_shape=state_shape,kernel_initializer=tf.variance_scaling_initializer(scale=2)))\n",
        "            self.network.add(Conv2D(64, (4, 4), strides=2, activation='relu',use_bias=False,kernel_initializer=tf.variance_scaling_initializer(scale=2)))\n",
        "            self.network.add(Conv2D(64, (3, 3), strides=1, activation='relu',use_bias=False,kernel_initializer=tf.variance_scaling_initializer(scale=2)))\n",
        "            self.network.add(Conv2D(1024, (7, 7), strides=1, activation='relu',use_bias=False,kernel_initializer=tf.variance_scaling_initializer(scale=2)))\n",
        "            self.network.add(Flatten())\n",
        "            self.network.add(Dense(n_actions, activation='linear',kernel_initializer=tf.variance_scaling_initializer(scale=2)))\n",
        "            \n",
        "            # prepare a graph for agent step\n",
        "            self.state_t = tf.placeholder('float32', [None,] + list(state_shape))\n",
        "            self.qvalues_t = self.get_symbolic_qvalues(self.state_t)\n",
        "            \n",
        "        self.weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=name)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def get_symbolic_qvalues(self, state_t):\n",
        "        \"\"\"takes agent's observation, returns qvalues. Both are tf Tensors\"\"\"\n",
        "        qvalues = self.network(state_t)\n",
        "        \n",
        "        \n",
        "        assert tf.is_numeric_tensor(qvalues) and qvalues.shape.ndims == 2, \\\n",
        "            \"please return 2d tf tensor of qvalues [you got %s]\" % repr(qvalues)\n",
        "        assert int(qvalues.shape[1]) == n_actions\n",
        "        \n",
        "        return qvalues\n",
        "    \n",
        "    def get_qvalues(self, state_t):\n",
        "        \"\"\"Same as symbolic step except it operates on numpy arrays\"\"\"\n",
        "        sess = tf.get_default_session()\n",
        "        return sess.run(self.qvalues_t, {self.state_t: state_t})\n",
        "    \n",
        "    def sample_actions(self, qvalues):\n",
        "        \"\"\"pick actions given qvalues. Uses epsilon-greedy exploration strategy. \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        batch_size, n_actions = qvalues.shape\n",
        "        random_actions = np.random.choice(n_actions, size=batch_size)\n",
        "        best_actions = qvalues.argmax(axis=-1)\n",
        "        should_explore = np.random.choice([0, 1], batch_size, p = [1-epsilon, epsilon])\n",
        "        return np.where(should_explore, random_actions, best_actions)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKZQAx98vzit"
      },
      "source": [
        "agent = DQNAgent(\"dqn_agent\", state_dim, n_actions, epsilon=0.5)\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0oplbmws0aQ"
      },
      "source": [
        "#Evaluate agents performance, in a number of games\n",
        "def evaluate(env, agent, n_games=1, greedy=False, t_max=10000):\n",
        "    \"\"\" Plays n_games full games. If greedy, picks actions as argmax(qvalues). Returns mean reward. \"\"\"\n",
        "    rewards = []\n",
        "    s = env.reset()\n",
        "    for _ in range(n_games):\n",
        "        reward = 0\n",
        "        for _ in range(t_max):\n",
        "            qvalues = agent.get_qvalues([s])\n",
        "            action = qvalues.argmax(axis=-1)[0] if greedy else agent.sample_actions(qvalues)[0]\n",
        "            s, r, done, _ = env.step(action)\n",
        "         \n",
        "            reward += r\n",
        "            if done: \n",
        "              s = env.reset()\n",
        "              break\n",
        "          \n",
        "        \n",
        "        rewards.append(reward)\n",
        "    return np.mean(rewards)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcEMOVr0vzi6"
      },
      "source": [
        "### Experience replay\n",
        "#### The interface is fairly simple:\n",
        "* `exp_replay.add(obs, act, rw, next_obs, done)` - saves (s,a,r,s',done) tuple into the buffer\n",
        "* `exp_replay.sample(batch_size)` - returns observations, actions, rewards, next_observations and is_done for `batch_size` random samples.\n",
        "* `len(exp_replay)` - returns number of elements stored in replay buffer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdfJ8uo_w0T0"
      },
      "source": [
        "# This code is shamelessly stolen from https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
        "import random\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size):\n",
        "        \"\"\"Create Replay buffer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        size: int\n",
        "            Max number of transitions to store in the buffer. When the buffer\n",
        "            overflows the old memories are dropped.\n",
        "        \"\"\"\n",
        "        self._storage = []\n",
        "        self._maxsize = size\n",
        "        self._next_idx = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._storage)\n",
        "\n",
        "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
        "        data = (obs_t, action, reward, obs_tp1, done)\n",
        "\n",
        "        if self._next_idx >= len(self._storage):\n",
        "            self._storage.append(data)\n",
        "        else:\n",
        "            self._storage[self._next_idx] = data\n",
        "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
        "\n",
        "    def _encode_sample(self, idxes):\n",
        "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
        "        for i in idxes:\n",
        "            data = self._storage[i]\n",
        "            obs_t, action, reward, obs_tp1, done = data\n",
        "            obses_t.append(np.array(obs_t, copy=False))\n",
        "            actions.append(np.array(action, copy=False))\n",
        "            rewards.append(reward)\n",
        "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
        "            dones.append(done)\n",
        "        return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Sample a batch of experiences.\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size: int\n",
        "            How many transitions to sample.\n",
        "        Returns\n",
        "        -------\n",
        "        obs_batch: np.array\n",
        "            batch of observations\n",
        "        act_batch: np.array\n",
        "            batch of actions executed given obs_batch\n",
        "        rew_batch: np.array\n",
        "            rewards received as results of executing act_batch\n",
        "        next_obs_batch: np.array\n",
        "            next set of observations seen after executing act_batch\n",
        "        done_mask: np.array\n",
        "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
        "            the end of an episode and 0 otherwise.\n",
        "        \"\"\"\n",
        "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
        "        return self._encode_sample(idxes)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9n13OfSJORS",
        "outputId": "87e37c65-8e0d-4610-afc1-e553d6fcce62"
      },
      "source": [
        "len(exp_replay._storage)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efn0J9MXvzi9"
      },
      "source": [
        "def play_and_record(agent, env, exp_replay, n_steps=1):\n",
        "    \"\"\"\n",
        "    Play the game for exactly n steps, record every (s,a,r,s', done) to replay buffer. \n",
        "    Whenever game ends, add record with done=True and reset the game.\n",
        "    :returns: return sum of rewards over time\n",
        "    \n",
        "    Note: please do not env.reset() unless env is done.\n",
        "    It is guaranteed that env has done=False when passed to this function.\n",
        "    \"\"\"\n",
        "    # State at the beginning of rollout\n",
        "    s = env.framebuffer\n",
        "    \n",
        "    # Play the game for n_steps as per instructions above\n",
        "    reward = 0.0\n",
        "    for t in range(n_steps):\n",
        "        # get agent to pick action given state s\n",
        "        qvalues = agent.get_qvalues([s])\n",
        "        action = agent.sample_actions(qvalues)[0]\n",
        "        next_s, r, done, _ = env.step(action)\n",
        "        \n",
        "        # add to replay buffer\n",
        "        exp_replay.add(s, action, r, next_s, done)\n",
        "        reward += r\n",
        "        if done:\n",
        "            s = env.reset()\n",
        "        else:\n",
        "            s = next_s\n",
        "    return reward\n",
        "        \n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C28S0910vzjI"
      },
      "source": [
        "### Target networks\n",
        "\n",
        "We also employ the so called \"target network\" - a copy of neural network weights to be used for reference Q-values:\n",
        "\n",
        "The network itself is an exact copy of agent network, but it's parameters are not trained. Instead, they are moved here from agent's actual network every so often.\n",
        "\n",
        "$$ Q_{reference}(s,a) = r + \\gamma \\cdot \\max _{a'} Q_{target}(s',a') $$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt3BJYRbvzjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ae7349-bf96-44ec-c0a3-930d4893a4af"
      },
      "source": [
        "target_network = DQNAgent(\"target_network\", state_dim, n_actions)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb9lUnZ0tAes"
      },
      "source": [
        "def load_weigths_into_target_network(agent, target_network):\n",
        "    \"\"\" assign target_network.weights variables to their respective agent.weights values. \"\"\"\n",
        "    assigns = []\n",
        "    for w_agent, w_target in zip(agent.weights, target_network.weights):\n",
        "        assigns.append(tf.assign(w_target, w_agent, validate_shape=True))\n",
        "    tf.get_default_session().run(assigns)\n",
        "    \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0IQNb3pvzjb"
      },
      "source": [
        "### Learning with... Q-learning\n",
        "Here we write a function similar to `agent.update` from tabular q-learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AbHB-60vzjc"
      },
      "source": [
        "# Create placeholders that will be fed with exp_replay.sample(batch_size)\n",
        "obs_ph = tf.placeholder(tf.float32, shape=(None,) + state_dim)\n",
        "actions_ph = tf.placeholder(tf.int32, shape=[None])\n",
        "rewards_ph = tf.placeholder(tf.float32, shape=[None])\n",
        "next_obs_ph = tf.placeholder(tf.float32, shape=(None,) + state_dim)\n",
        "is_done_ph = tf.placeholder(tf.float32, shape=[None])\n",
        "\n",
        "is_not_done = 1 - is_done_ph\n",
        "gamma = 0.99"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Ss1UJtvzjf"
      },
      "source": [
        "Take q-values for actions agent just took"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1qFprBwvzjg"
      },
      "source": [
        "current_qvalues = agent.get_symbolic_qvalues(obs_ph)\n",
        "current_action_qvalues = tf.reduce_sum(tf.one_hot(actions_ph, n_actions) * current_qvalues, axis=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op08x3u0vzji"
      },
      "source": [
        "Compute Q-learning TD error:\n",
        "\n",
        "$$ L = { 1 \\over N} \\sum_i [ Q_{\\theta}(s,a) - Q_{reference}(s,a) ] ^2 $$\n",
        "\n",
        "With Q-reference defined as\n",
        "\n",
        "$$ Q_{reference}(s,a) = r(s,a) + \\gamma \\cdot max_{a'} Q_{target}(s', a') $$\n",
        "\n",
        "Where\n",
        "* $Q_{target}(s',a')$ denotes q-value of next state and next action predicted by __target_network__\n",
        "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
        "* $\\gamma$ is a discount factor defined two cells above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiY2T2mYvzjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d7977c-788b-4a53-fe1f-9e06fd8b3e36"
      },
      "source": [
        "# compute q-values for NEXT states with target network\n",
        "next_qvalues_target =  target_network.get_symbolic_qvalues(next_obs_ph)\n",
        "\n",
        "# compute state values by taking max over next_qvalues_target for all actions\n",
        "next_state_values_target = tf.reduce_max(next_qvalues_target, axis=-1)\n",
        "\n",
        "# compute Q_reference(s,a) as per formula above.\n",
        "reference_qvalues = rewards_ph + gamma*next_state_values_target*is_not_done\n",
        "\n",
        "# Define loss function for sgd.\n",
        "# td_loss = (current_action_qvalues - reference_qvalues) ** 2\n",
        "td_loss = tf.reduce_mean(tf.losses.huber_loss(labels=reference_qvalues, predictions=current_action_qvalues))\n",
        "\n",
        "optimizer=tf.train.AdamOptimizer(1e-5)\n",
        "train_step = optimizer.minimize(td_loss, var_list=agent.weights)\n",
        "\n",
        "sess.run(tf.global_variables_initializer()) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xPdpbz3vzjs"
      },
      "source": [
        "### Main loop\n",
        "\n",
        "It's time to put everything together and see if it learns anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63uX3u0-c5iN",
        "outputId": "4367a287-e7f1-40c7-f95e-20820fc4a495"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIXESnjDY6W8"
      },
      "source": [
        "#Uncomment to load stored weights of trained agent.\n",
        "weights_path = '/content/drive/MyDrive/Colab Notebooks/dqn_model_atari_weights.h5'\n",
        "#agent.network.load_weights(weights_path)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwvsqiQavzjw"
      },
      "source": [
        "#Create the buffer and fill it.\n",
        "exp_replay = ReplayBuffer(70000)\n",
        "play_and_record(agent, env, exp_replay, n_steps=10000)\n",
        "\n",
        "# take a sample batch of observations from the buffer\n",
        "def sample_batch(exp_replay, batch_size):\n",
        "    obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch = exp_replay.sample(batch_size)\n",
        "    return {\n",
        "        obs_ph:obs_batch, actions_ph:act_batch, rewards_ph:reward_batch, \n",
        "        next_obs_ph:next_obs_batch, is_done_ph:is_done_batch\n",
        "    }"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGQPR9Dvvzjs"
      },
      "source": [
        "from tqdm import trange\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import DataFrame\n",
        "moving_average = lambda x, span, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(span=span, **kw).mean().values\n",
        "%matplotlib inline\n",
        "\n",
        "mean_rw_history = []\n",
        "td_loss_history = []"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Wee4pdpKvzjz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "b40e1a44-b305-4d1b-f884-58d2cbddb479"
      },
      "source": [
        "##Train the agent, configure the starting epsilon to one to encourage exploration\n",
        "agent.epsilon=1\n",
        "for i in trange(100):\n",
        "    \n",
        "    # play\n",
        "    play_and_record(agent, env, exp_replay, 10)\n",
        "    \n",
        "    # train the network\n",
        "    _, loss_t = sess.run([train_step, td_loss], sample_batch(exp_replay, batch_size=64))\n",
        "    td_loss_history.append(loss_t)\n",
        "    \n",
        "    # adjust agent parameters\n",
        "    if i % 500 == 0:\n",
        "        load_weigths_into_target_network(agent, target_network)\n",
        "        # reduce epsilon in every iteration until it reaches 1%\n",
        "        agent.epsilon = max(agent.epsilon * 0.999, 0.01)\n",
        "\n",
        "    \n",
        "    if i % 5000 == 0:\n",
        "      #uncomment to store agent's weights every some iterations\n",
        "#         agent.network.save_weights('/dqn_model_atari_weights.h5')\n",
        "        mean_rw_history.append(evaluate(make_env(), agent, n_games=3))\n",
        "        \n",
        "    if i % 500 == 0:\n",
        "        # plot mean reward per game and TD loss history\n",
        "        clear_output(True)\n",
        "        print(\"buffer size = %i, epsilon = %.5f\" % (len(exp_replay), agent.epsilon))\n",
        "        \n",
        "        plt.subplot(1,2,1)\n",
        "        plt.title(\"mean reward per game\")\n",
        "        plt.plot(mean_rw_history)\n",
        "        plt.grid()\n",
        "\n",
        "        assert not np.isnan(loss_t)\n",
        "        plt.figure(figsize=[12, 4])\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.title(\"TD loss history (moving average)\")\n",
        "        plt.plot(moving_average(np.array(td_loss_history), span=100, min_periods=100))\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buffer size = 70000, epsilon = 0.88687\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAEICAYAAABs2F48AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZwUxfXAv49dWG7Q5T5kOUW8ATlUdAweKEZMoolHEk00xERjvPILRmOMR6LmMCaaqFETo0ZRo4YIggeMitzIfS/3fV8LLOxRvz+6Z7enp2eme6bnru/ns5/t6a6uet1d/brq1atXopRCo9FoNNlDg0wLoNFoNJpwtGLWaDSaLEMrZo1Go8kytGLWaDSaLEMrZo1Go8kytGLWaDSaLEMr5jxDRG4UkalpKqtMRJSIFEc5/gsReSEdsnhFRH4oIn/KQLkVItIj3eXmAiJSIiLLRaRtpmXJNFoxZxDzJQ391YrIEcvv60XkQRGpEpGD5t9KEXlaRDpmWnY3KKV+o5S6OV46EQmKSNx0fiEijYD7gd+lq8wQSqnmSqk16S43F1BKHQVeAsZkWpZMoxVzBjFf0uZKqebABuCrln2vmcnGKqVaAMcDXwM6AHNzRTmnGjHwWo9HAcuVUptTIVM+E6135CP/Bm4QkZIUl5PVaMWcIyilqpRSS4BvATuBu92cJyJni8hsEdlv/j/bcuxGEVljtsbXisj15v5eIvKpec4uERkbp5jrRWSDmfY+S/4Pisir5nZjEXlVRHaLyD5TlvYi8igwDHja7Ck87ULuoIg8KiJfAIeBu0Vkru267xKR/0aR91LgU0vakEnmeyKyUUT2isgtInKWiCw05X3akr6BiNwvIutFZIeI/EtEWpnHPhCR22yyLBCRr5vbSkR6mdv/FJFnRGS8+QxmikhPy3kXi8gK8x781Xwmjj0LERkkItNNWbeaPatG5rG/icjvben/KyJ3mdudROQ/IrLTrAe3257h2+azOwDcGKssN3KLyPdFZJl5nyeJSLfQMaXUJmAvMCTKsysMlFL6Lwv+gHXAhbZ9DwKvOqR9CJgZJZ8bganm9vEYlfw7QDFwrfm7FGgGHABONNN2BE42t18H7sP4cDcGzo1SVhmggL8DTYDTgaPASXb5gR8C/wOaAkXAAKCleSwI3GzJN6rclvQbgJPN4yXAnlC5Zpp5wDeiyD0buNrhOp41r/dioBJ4D2gHdAZ2AOeb6b8PlAM9gObAO8Ar5rHvAl9Y8u4H7ANKzN8K6GVu/xPYDQwyr+M14A3zWBvz+XzdPPZToMp6n2zXNABDmRWb17MMuMM8dh6wERDz93HAEaCT+YznAg8AjcxrWgNcYnmGVcCVZtomccqKKTdGb6UcOMk8fj8wzXYt44DbM/1OZvJPt5hzky0YyiseI4FVSqlXlFLVSqnXgeXAV83jtcApItJEKbVVGS1yMF6kbkAnpVSlUireYOKvlVJHlFILgAUYCtpOFcYHoZdSqkYpNVcpdSBBuQH+qZRaYh4/CowFvg0gIidjKIz3o+TfGjjosP9h83o/BA4BryuldijD5PE5cKaZ7nrgj0qpNUqpCuBe4Bqzm/8ucIalFXg98I4poxPvKqVmKaWqMRTzGeb+y4AlSql3zGN/BrZFyQPzfs4w78c64DngfPPw5xgfhGHm76uA6UqpLcBZQFul1ENKqWPKsH//HbjGkv10pdR7Sqla8znHKiue3LcAv1VKLTOP/8Z2v8B4Nq2jXWshoBVzbtIZo4UYj07Aetu+9UBnpdQhDLPILcBWszvd10zzf4AAs0RkiYh8P0451hfvMEYr0s4rwCTgDRHZIiJPiEhDr3Jbfm+0HX8ZuE5EBKOl/WYMZbgXaOGwf7tl+4jD79B12eVbj9H6a6+UOgiMp16xXYuhcKMR7d51wnKNymhKboqWiYj0EZH3RWSbaXL4DUbrNXTuG6YsANdZZOoGdDLNEvtEZB/wC6C9Jfuwex2rLBdydwOespS1B6OuWZ9tC4xeRsGiFXOOIcZA11cxWkHx2ILxIlg5AdgMoJSapJS6CMOMsRyjpYRSaptS6gdKqU4YJoi/huyiiaIMG/mvlVL9gLOByzG6/WC05lzL7XSOUmoGcAyjVXgdxocgGguBPp4uILZ8JwDV1Cvy14FrRWQohmlkSgJlbAW6hH6YH5wu0ZPzN4xn2Fsp1RJDuYrl+OvAVWbLdDDwH3P/RmCtUqq15a+FUuoyy7n25xOrrHhybwR+aCuviVJqmiXNSRg9r4JFK+YcQUSKReQkjBesA/BHF6dNAPqIyHXm+d/CsHm+L8bA2ygRaYZhF67AMG0gIleLSOhl2ovxYtYmKf8FInKqiBRh2CCrLHlux7BtxpU7TjH/Ap4GquKYXyZQ3/VOhNeBO0Wku4g0x2gxjjW75qH8u2GMBYxVSiVy78YDp4rIlaaJ5FaM5x6NFhj3tcLs+fzIelApNQ/YBbwATFJKhVqks4CDIvJzEWkiIkUicoqInJVgWfHkfha41zQ3ISKtROTq0EER6YxhppsRo/y8Ryvm7OdbIlIB7McYFNkNDDDtgzFRSu3GaJnebZ73f8DlSqldGM/+LozW3x4MRRV6wc4CZprljgN+qpL3ve0AvI3xQi/D8IoItWqfwmjN7RWRP8eROxavAKcAr8ZJ9z+gr4h0SuhKDF/bV4DPgLUYA4U/CR00TSjvABdiuH95xrzWq4EnMO5BP2AOxkfUiXswegoHMXo+Tp40/7bLpJSqwbjXZ5jXElLerWKIF7WseHIrpd4FHscwaR0AFmN4yYS4Dng5hhmqIAiN0mo0OY+INMHwnuivlFoVJ+1ooJ9S6o60CJckpglrE3C9UioR00hG8CK3GL7LC4DzlFI70iFftpJqZ3GNJp38CJgdTykDKKWeT4M8SSEilwAzMQYef4Zhx836Ln6icput5L7x0hUCWjFr8gIRWYehAK7MsCh+MhTD7NAIWApcqZQ6klmRXJGrcmcN2pSh0Wg0WYYe/NNoNJosw5UpQ0RGYIycFwEvKKUesx0vwXBVGoAxEvstpdQ6EbkIeAyjS3MM+JlSarJ5zgCMKalNMNyLfqriNN/btGmjysrKXF8cwKFDh2jWrJmnc7KFXJU9V+WG3JU9V+WGwpF97ty5u5RS7kKaxpuzjaGMV2P4mTbCGDXtZ0vzY+BZc/saDN9NMKawdjK3TwE2W86ZhTHfXoAPgEvjyTJgwADllSlTpng+J1vIVdlzVW6lclf2XJVbqcKRHZijfIyVMQgoV0ZcgGMYUztH2dKMwpgSC4av6nAREaXUPFXvb7sEaCJGMOyOGAFsZpgC/4v8GrTRaDSahHFjyuhM+Fz5TRhTOh3TKKWqRWQ/RsAa64SAbwBfKqWOmrN7rPPnNxE+V74O0990NED79u0JBoMuRK6noqLC8znZQq7KnqtyQ+7Knqtyg5bdibS4y5nTLx/HCKfoCWX4mz4PMHDgQBUIBDydHwwG8XpOtpCrsueq3JC7sueq3KBld8KNKWMz0NXyuwvhwWTC0pjz41thDAJixlx4F/iuUmq1Jb01sIlTnhqNRlOQuFHMs4HeZsCWRhiDe+NsacYBN5jbVwGTlVJKRFpjBDUZo5T6IpRYKbUVOCAiQ8zoU98Foq02odFoNAVFXMWsjIhZt2HE0l2GEed2iYg8JCJXmMleBEpFpBwjME5oMcXbgF7AAyIy3/xrZx77MUawlHIMr48P/LoojUajyWVc2ZiVUhMwfI2t+x6wbFdiRJSyn/cI8EiUPOdguNBpNBqNxkLez/ybubWa/YerMi2GRqPRuCavFfP63Yf424Kj/HTsvEyLotFoNK7Ja8VcWWUsHLF5rw5spdFocoe8Vsy7K4xFEFbtqMiwJBpNfCqrajItgiZLyGvFPGudm4WkNZrM886Xm+j7y4ms2akbEZo8V8wNROIn0miygElLtgGwYtvBDEuiyQbyWjEXNdCKWZMbhOpqjV64QkOeK2bdYtbkCqG6Wqv1soY8V8xFeX11mnyiTjFrzawhzxWzbjFrcoU6U4ZWzBryXDGn28b8waKtfGgO4mg0Xgi1IWq1jVlDnivmdLeYf/Tal4x+ZW5ay9TkB6G6Gk8vK6X4z9xNHDmmfZ7zmfxWzNorQ5MjFIk7r4zpa3Zz91sLeHj80nSIpckQea2Yi7SNWZMjuK2qFZXVAOw4cDSF0mgyTV4rZt1g1uQa7k3MzglXbT/Isepa3+TRZIb8VsxaM2tyBLctZomRcNv+Si568jMe/N8Sn6TSZIq8VszalKHJV5xa1vuOHANg7rq9aZZG4zd5rZgb5PXVafIRFcVEoSks8lp1VRzVLkWaXMFb7053BvObvFbM63YdyrQIGo0n3A7+6Xko+Y0rxSwiI0RkhYiUi8gYh+MlIjLWPD5TRMrM/aUiMkVEKkTkads514rIIhFZKCITRaSNHxdkRUeX0+QKrgf/UitGVvLUx6v46l+mZlqMtBJXMYtIEfAMcCnQD7hWRPrZkt0E7FVK9QKeBB4391cCvwTuseVZDDwFXKCUOg1YCNyWxHU4ohWzJl8ppAbzkx+vZNHm/ZkWI624aTEPAsqVUmuUUseAN4BRtjSjgJfN7beB4SIiSqlDSqmpGAraiph/zcTw/2kJbEn0IqKhvTI0uUYhKVxNdIpdpOkMbLT83gQMjpZGKVUtIvuBUmCXU4ZKqSoR+RGwCDgErAJudUorIqOB0QDt27cnGAy6ENlg44ZjddtezksWv8qqqKhIq9x+katyQ+Zk37rFXJ9y5UqClWujplu0w5j5t3v37jA5KyoqmD17DgCHDuXW/Xd7z7PxmlJVX9woZt8RkYbAj4AzgTXAX4B7gUfsaZVSzwPPAwwcOFAFAgHX5SysWQWrVwLg5byEmTje17KCwWB65PaZXJUbMif7R3sXwcYN9O7dm8DQsqjpapZthy/nUFpaSiBwVt3+YDBIr7794YvPadasOYHAeWmQ2h+mTJlCp5MG0Kd9C+cEPr9XfpKq+uLGlLEZ6Gr53cXc55jGtB+3AnbHyPMMAKXUaqWUAt4EznYps2u0jVmTK4SsboVoyghurObiJz9jWrljB7sgcaOYZwO9RaS7iDQCrgHG2dKMA24wt68CJpsKNxqbgX4i0tb8fRGwzL3Y7tCKWZOvxH69EmPy8u2s351+F9N1B4zYHut2H0572dlKXFOGaTO+DZgEFAEvKaWWiMhDwByl1DjgReAVESkH9mAobwBEZB3G4F4jEbkSuFgptVREfg18JiJVwHrgRn8vDYq1YtbkEfM37uOmlw078pQVO6msqqFxwyLf8v/+P4281z020rc83VCIvYR4uLIxK6UmABNs+x6wbFcCV0c5tyzK/meBZ90Kmgi6xazJFYT4gfLfmrMx7PdTn6zi5yP61v3O9Ukn2omqnrye+afX/NPkColU1VBs5hBfmDbaFdsP+iFS2tDLHEaS34pZt5jTTnVNrV5QNAli2Y7tR+zK/JHxvg/TpIWpm40PzL7DVRmWJHvIa8WcKRvz3PV7MlJuulm29QBnPPQhOw/Wr6ZxzuOTueVjPYjjloOVVRytTizYVr41O/Yf0Yo5RF4r5kzN/Fu6Nbe6konywudr2Xe4iuCKHXX7th84SpVeQMM1pz74IV//67RMi5EVaMtjPfmtmLUpQ5MDLNlyoK71q41A3pm9bg8VR6vjJ8whtGLWJEwoqHus5Y407kj3PaytVVTXZFfXRjDGKH782lyWbT3g6pw9h45x9bPTuf31eakVLs3ktWLWg38pxmze1bX2ct1fKwvwcgvjKfPVOyuojTIQe/0LM+l13wdeREs5DURYub2CCYu2cefY+a7Oqawy7PNuFXmukNeKWUeXSy32V147Y2QPizfvZ/gfPuXvn69xPD59TayICblHvrUJ8lsx5/XVZZ5QCzn0/avNt7cjy/ByezfuMTxj5m3YlyJpUoPXtlS+tr0yEl0uXWjbZ3qoC8Cj9XLSeLmFiVTvfYeP8dD/lno/MQ1Yr8drXcq3RWzzuk2ZjaaMm1+eTdmY8ZkWwxfsr0K+vRzpJF1V9enJ5bwzzx4cMjuw3oK1LtfrlLzz5jbIb8WchYN/Hy/bET9RjqDqBv/ix3nQuMM+gFpZVcOOA/YFgPIUy9fpmEePkXyre3mtmLVXRmoJvQtZ2DHJOaK1/G56eTaDfvOJp3Ni4VXhpROBsOn8SqmoXiV15+RpHOu8tjFnoykjn9GDf/7zRbm/3hOvzFjva35+Y1XM3e+dECOlQb6+4XneYs60BPmNvdut9XLivPRF9HX+/CSbn9GRqhqqaxNr0WfzdSVCXqsuHfYztdSbMiTstyZVhN/hfKvez3+2hnYtGns7Kc/uQYi8VsyndWmVaREKAj3zzz8K/RaGBuzbNG/k8czU3LjyHQc59cFJbNl3JK3hbPNaMTdtlNcm9MwT8srI0wGYTOCXy+GPXvvSl3yynVS7y706YwMHK6u5/fV59PzFBFbvrEhpeSHyWjFrUktdEKOQu1z2DvjnDJUFHjM10c9Sqnsac9bvBWDplvTE5CgIxdyjbbO0lrd575G64CqFRKFMMFFKcbAyNUHdV+2o4J9frHVVf/LUvOqJVNvZ/zltXdjvdNVwV4pZREaIyAoRKReRMQ7HS0RkrHl8poiUmftLRWSKiFSIyNO2cxqJyPMislJElovIN/y4IDstG8HQHqWpyDoqz366mh/8a05ay3Ri4uJtKf1AKLspI4v08ux1e1ixLTULFvxz2jpOffDDungUfvL+wi08+L+lPPnRSt/zzgUSHafIoqrnC3EVs4gUAc8AlwL9gGtFpJ8t2U3AXqVUL+BJ4HFzfyXwS+Aeh6zvA3YopfqY+X6a0BW4IBMP7fNVuzJQaj1z1+/hllfn8mgK14Grn/ln/k5ZSd65+tnpXPKnz1KS96Ql2wBSophD99Rp/bt0daOrsngSip109xq270/PLEw3LeZBQLlSao1S6hjwBjDKlmYU8LK5/TYwXEREKXVIKTUVQ0Hb+T7wWwClVK1SKkWarDA7fKEXe9Pe1K2/ZzddFMoEkwYZcg9csGl/2O9UdeMP5ODae+nyCHp0QnoWvHXjttAZ2Gj5vQkYHC2NUqpaRPYDpYCjshWR1ubmwyISAFYDtymltjukHQ2MBmjfvj3BYNCFyPUoVcuWzVsIBtMffzaWrG6uo6KiwvP1hli0w1hqZ8+ePQnnEY/Zqw2l/8msRTTZvYIDR+tfjlSV6RWvcri55/v2HQFg/vwFVG0qSlCy2GzdtpVgsH5RXyeZNm7cSDBoxF7Zs78Cp0bIzl07PdfDadOm0aKRs9Y/VqNYsruGM9ulxuNp+vQZRjnHjkUcc5L14DGjzlVVVYUd31NZS5NioUmx/18vaznJvKOxyJQ/WTHQBZimlLpLRO4Cfg98x55QKfU88DzAwIEDVSAQ8FRQgykT6NipE4HAqUkLHZeJ4VHjHGU107i5jmAw6CqdEzXLtsOXcygtLSUQOCuhPOKxx7yW9VXNCQTOZsfBSphixHVIVG7f8HCfrbi5538vnwG7d3Pa6acxrHfbsGNKKf47fwsjTulA44YulPZE50iDHTt0JBA4re7408saAeER17p27UogYFgVH3ntIyBSmbVt05ZAYEDd76ErZ4QFyQ+7VrOsc845h+ObOfsR3/fuIl77cgPv3TqQM7q2dkzjGcs9GDJkCHw2hUaNGoFNOTs9lz2HjsHkj6ihiJP6D6F9S2OCStmY8fRo04zJ90Sek6hsTnIk847Gwo0pYzPQ1fK7i7nPMY2IFAOtgFhN1N3AYeAd8/dbQH8XsiRIYXSxM0WdL2mB3OZYvrNflO/mjrHz+W2MLm9VTS3TV3vrwYXctcLkSMCWccYJ8ZVprFzX7zZ6SanySonFF+W7eCHKiixHqmoYbAv2tMZl6NBsxI1ing30FpHuItIIuAYYZ0szDrjB3L4KmKxiGH3MY/8DAuau4UBKoneny8J86VOfez6ntlYxrTw1pvV0mnsLbYJJLC+UkMLaFiNU5+8mreDav89g/sboq4t4dT1Mtp5b18yLpe9D4wiZiIN8/QszeSSFg9nZRFzFrJSqBm4DJgHLgDeVUktE5CERucJM9iJQKiLlwF1AnUudiKwD/gjcKCKbLB4dPwceFJGFGCaMu326poRZsHEfZWPGs3X/Ec/nJrIY5ItT13LdCzOZvDzCtJ6TFMrgXwin662LGxLjVqzabrjx7a44mhK5YhFNnVobFnalu2DjPjaYLeXQdSUaUbemNnYozwKrQlFxZWNWSk0AJtj2PWDZrgSujnJuWZT964Hz3AqaDG4fdigk4uerdvHNgV3jpE6eUFdraxQXnCW7alj12Rp+cF6PlMviB4XyUsUyIdSvfxi+f+fBo7w5ZyM/GNbDlfJ2cy+Fepu22wmD6xNw8Rv1zBcArHtsZP3HKEHF3PMXE+jZthkT7ziPhnpRzqjoO+NEliiY382pTNg9py7ym3/iuC4z34nlt73E9DXeWXGUqat28ddgOQC3/vtLfjdpBRc9+akrv2+39zK4cid3jJ3Pf1ZGDvw5EWr5xiRGpalvMSdes1bvPMStUWJ5pNuEk60UhGJ225Krf2FyU8U8/P5SBv/m46TzGfX0VAK/m+I6fV0rMY3RtzJJvY058npfmmrEVV6wcR/ffnEmT0xcARiLoIIxeBZqMa/fHTk41bdDC6MMF3Ks2lFR53N80OVYnCsTRIzHGGoxJxtS98OlqTHfHa3Oj1AIea+Y8/WL6sSLU9ey/UDydssFm/azLk7LavHm+skO+bogZjQSuVrrPQrptKPVyc2w27a/kr2H3LWUQyS73Foyy4lNdTEbNllz2Oy1kd4ruUjeK2bI3RawH6RqdtgTk1ZElBHrpdpxsJK3525KjTAxqE7B9OJQi9fLYhvW5+AmfrWbGquAv0wudy8ERMQPOXysmvvfW2TLN9bgXKjF7KlYAL794kzvJ8WhOk97aXmvmL0opkSD8XwnBRUu23FSKk4v9Nz1e/jle4u56Z9zuOetBew8mHyL/u+freGPH66In5DUvLixqpSbqcGhemafYp2QLB4V5OFj4V39f05bx6szNoTti3UJoduZiA+1G7w+rbGzbbLbcijfUcFfPlnleO68DXu5c+z8rDTB5b1iBi825sRiIGQ6YJETmVhNxKnIb/xtOq/MWM9206/Xj1UgHp2wjD97bCm6pVYp/vLJKlcmAi9X4qTIPkrSzjq4+/FJK0ivSknV+TGnll0V7kw0Byurw37b6+A1z0/nDx+t5IDDhJjv/3M2787bzL4sjA1SEIo5k1TX1BrTRjOG8QodOlrNGh9XX7D68Na7iMV/ybPZrLR0ywEmrK3iDx+t5BfvLoqazmnw75kp5VFnpUG4IvPLJt+spCjpleCdHtlLX6x1nDA1Y83uuqdnH/wrGzOeB/67OClZDHk8figcfi+wTNw5avoROmWbCc8ltxSEYs6kKvjVuCX0f/gjjhzzf7TYywj09/4xm6/8wb/IqtaK7qan4eUZLNy0L+asuFRx2Z8/5+2VRuvpUMznFfkq/27Sipiz0sJszDE0wXIPMaSVSnyiRyz+MrncccLUc5+urp/551Duv6av91+YOESu1K5Yvs0iuynn6b/+kNtfnxeWPtRbiOZh4nVg1U/yXjHvqVS8N88e2sOZVAR8H79oK0BEwPpkTQ1LtxzgxPsnMnHxVlfpZ63bE/a7sqrG08dCKcUbszbUXYdjC8Sn+3bF019wpTmpIZVMXLw1akxl6/PZsu8IZWPG8/7CLQDMNIMAOV1ubIVu4Kd5NllTxh9iBOR/7tPVEfuqa/xxl4uG1ypkr3P231Ypxy3Ywow1eyLSShQteM3zMzxK4x95r5jB/QBQLi0Hv2iz0aKcvHyH4/HQFe886Dyr8OzHJnPSAxNdl/fh0u2MeWcRfzAH3awmifr7lpqptr+btJyyMeMj7NNlY8Y72g7dlnvLq19y2Z/jxzgJtcBCXiUHj1bHzTsWfroXNkjhG/zbD5aH/RaRuhb9Z6t2pq5gD0SaMpTNNTH8XlccrbdJx/PJXrE9NSvguKEgFLNXUmEHjahAynnbc75Rzg1NaIg28u/V7h0aZNltDso4lZuqwe3nPjVst04Dh2t2JhdB7GBlNQMf+Shiv6OpJonrk3Ajc1yUij8wp0hdy9WxPMsN2ONycC7VOLWYnRsNkdR5mNj2V1bVcOhodUT6dKIVcxj+V/JoOSarw+K1uqpq3JVgdfqfu34Pm/c5B3Cyl2bNvcJVCzLxK441qWHvoWP8/O2FSa1t6OQBEPZxjho9z/01bd5bf1/HL3RnfnKTezzFnKrB1qKi6OWu3llB2ZjxzF2/J2qaaCRrDovXOLB+XEL3poEIZWPG8ytz8HLQox9z8q8mJSdIkmjF7EA6PM2sFcTvRs/R6homLHL38lud/r/xt+mc+/jkut9lYyKDhKuIDZi3YZ+5K/qN2xWjpR2PWC5aT0xawdg5G6OOIySqmFSkXo7KDS/NipvfXoc1/JJFqfiyTVqy3bFHkAjBlfXmi1jeIJ+b6X7y73k8Oj4l0XzrcFreLMyUEePcStNjI3QpL5uDlwcqM9taBq2Yw4hW144cq+FPH69MapHKiNFjqBu42xKllZooj3+wgmlRArHHC2nqVnE6ucal6oNW32KOfECp6sg7D27aPQCM/5+ujG1vdfrA+YHChWbGvU9w3PKs5jeMEABO70ToOW3ZX8nfP1/rtRRPqe3lK6U4fKxesdrrjFPuG1KwqG6yaMXsgP3h/WXyKv708SrGzt7omD4W0UbNlapvRfm9+nEsRb82SZtsCKcKnjLFHMUWCPEHv/o9MCmh2YbWllg0c0EqO1b/+XITPX8xIW66IT1KXeW340Clr5OO/j1zAw+/v7QuaJMVLz3AcQu2hP3+dKW3yVr2WYu1Ktwzxo0oqXBlTRatmC1Ee4hHTPul16AzsVrY4QMUibf7nF61mNklWJR9UoXTS56JQPmhbus7MVwiVycwsSbMlOFhAk266dGmmat0g37zCW8k0LCIRuidOFBZxTtfhsdAcVvFVm0/yO2vzwvb9/D78U0fsdxf52/cF+YCaX8XnB6hH3rvHBcAACAASURBVGEC/EYrZhfUj8orjlbX8MLna1wFx3lj1oa4aUL5JiBUQiTqqmWv4Mccrv8H/5qTUN5u2eHwAoUmWMxaG32gKZHbO3PtHsp3GAo92j3LuJ72WP4Hi7f5VnTIxqwU3PXmgvCDLhsaSxLsKc6JMaj4/GdrbB8gZ1nWWdYDzEY3Wa2YnbC9cdaJJ3+dsppHxi/jLReR0o5YPAViuctNWeGvT6g9UI2VZCthSOzFmyNfqmgrsfjFkN9+EuaHCu56G4kOAI7402fh+diyScYTxA+8XtVncWzhXji5U8uEZLCSSYUY+H0wc4W7oGAU87eemx43TbRFRa0B9EP+vG78HFMZtOpTU5l/4OB9EStQULLvwlyH1ZpThdNK0gtsU7UTnZJsV/BOhCYmRZsRevdbC1zPKs03GjcsApx7DW4fyVG362HZeHXGBtfmqUjln+lujjsKRjHPjNHVjYf1xfQybTvemm4tG4cvuVhxtJo+933ApCXb4sYuXrLFmDhy6FgNtbXKcRDGiWSn8G7am5wHiZfX4ic2+yNE3lP7wNzuiqNc/0L8qbSullgyiXXHPlzqn3kgl6hvxCSu6J78OPp08Hi4XV0+wv8+N/SyO8UsIiNEZIWIlIvIGIfjJSIy1jw+U0TKzP2lIjJFRCpE5OkoeY8TkeTDUqWQusUz8dbiNKaHmtv2GUooimzNvdU7KjhWU8sPX5nLPW/Z7HYx+GjZdh5yMWgCiXcfl2/NxPRUpykd4fuW2oLtvDZzA1+Uh7e0ndzF3N6HTXsPs3HvYceyASYsypxiTkdo17g9giRESCbqolvzXzbaj90QVzGLSBHwDHAp0A+4VkT62ZLdBOxVSvUCngQeN/dXAr8E7omS99cB/2JRJkm0qbdOytVNSyFei9ne2ku0EtndfWLlk2g9fe6z6CEtveBFmThZZOz73Nh5Z6yJNIm4vdfnPj6Fn//HCAGaK60tP7lj7HzH/dbGSjy+62ICjlesvsqx2Hso/sSebHyublrMg4BypdQapdQx4A1glC3NKOBlc/ttYLiIiFLqkFJqKoaCDkNEmgN3AY8kLL3PRF1k09Jts5syYimaeFNv7WaFROMe2D8S623ddGt40EzXQetyTHsOHeOB/y7mWBQ3RDcueREfN8d8PIsZRR5/8skH6hsr8W/KZyt3+r5IqtsFF+zeQ05nbY8S6CuTFMdPQmfA6n+yCRgcLY1SqlpE9gOlQCxD0MPAH4CYxj4RGQ2MBmjfvj3BYNCFyM7EO3fzZsMda1V5OcGq+tiyGzcYXa41a9YQ6hWvXrOaoNoYs2Iu3XqAlo2M7WnTptGqpF5tfPb559RU1XflgsEg6w84V14nuY8cqbf1vvRJuCXIPpPpn+Pqz//Xh3M41KdR2PGn3/6EU9oUuS7bzb5o9/qB1z/nxlNKAHhh0VGmbq6m8aFtnN0psioeq6qKyOfTWeEmHmvkwGAwyNp1kd3jrVu2EAyGt5o3Hgx/YV947xNHea3MWreHM38Vf9JHutiwYSMVTTIzTLR3jzFms2FjuG90MBhk5YbIVurI338Ysa/Gy6KJNnbu2Z+QLli8ZAlNd4cvS/be9Po42m7ytKapqKhISidFw41i9h0ROQPoqZS6M2SPjoZS6nngeYCBAweqQCDgrbCJ9dNh45374d5FsGEDvXv1InBO97r9M44sh7Wr6d69B/uPVMG6NfTo0ZPA+T0NxTwp+staTRFQw9lnn03bFiV18gwacjZNZk9l79HKOtmWbNkP06ZG5OEkd+PZU+CwoYCripsC0W3AHXr0hVlGl7RD5y4EAv3C7kvj9t0JDOsRts9a9qm2gC6BQCAirX3fCScPpEfb5hHp9tCMQOBcAP67fT5s3syJJ/YlMKBLfSLznKKi4oh8e/XuA0uchyQCgQBLVDmsCn/xOnTsSCBwWti+FdsOwhf17nCPzHDXatp7NHuazZPWV3P/yJNgefQA/amitPR42LWTLl26wrr6gedAIMCmGethafgzKt8XqYQbNGjgbUVbC02aNScQGOZYZ2Nxcr+TCZzWMey8tm3bwjZjrODMQefAxMiPiBXr+xgMBuPqlURw87ndDHS1/O5i7nNMIyLFQCvAOViDwVBgoIisA6YCfUQk6E7k1PHvmcaEkC02f1xrfAm7vTleTy7kU3zWox+H7b9j7HxDyVvwM06vlQNx1jSLdw0HEwiB+OD/nAcjvcyec5z27VkSaFQcWc1zdVDITqamE9etFO7wPF3f2yS+cX4uoGr1ye/vU8CnZHGjmGcDvUWku4g0Aq4BxtnSjANuMLevAiarGH18pdTflFKdlFJlwLnASqVUwKvwqWK3bRT/v/ON+fxrdh7yLWrO56t2Rax2kSplse1A7NagQkUdIQ/FdY6H3U68eofzmK4XO61T2qo40+Kd7uGw3m0j07kXI6uJtQJJKsn0/evQqnFC5zkN2lvnJPixWLAfxFXMSqlq4DZgErAMeFMptUREHhKRK8xkLwKlIlKOMaBX51Jntor/CNwoIpscPDqyjnkb9jourLlx72HW7wq3387f5H5tOus0UCeiKebzfzeFkTFW2oin7KwfmmhLQtlb7yHcOvL/LRi+DFG0uM7WabjxXm6nb/srM2KvK5eqXocmnFQsw+aF3u2a1628nizZoYrDcWVjVkpNACbY9j1g2a4Ero5yblmcvNcBp7iRI12s2XWIR8Yv4+ZhPcL2W+MxhL68335hJrHo0LJxXYs13jTQaF4ZIS+L12au5/rB3SKOx3Pds/tLO3FBFNncvngLPHyg3OLUeIn2AQnhdAuT6m5romDcwG02s99Vf5tGd5eBlZKZnPLC1LW84HJSlZ9c3K99WsopmJl/ENnd9oNYcSm8Ek9X3Pdu/YDKwG7Hu8632KKYd1V4i6Tl9tWJtvZgMji9uP5FeNOaORlCVWrikvAJNnPW73UVRwbcr7LjJ27ibMeinxkjJNUUlGLuc/8HrEkgBKQTbp+l25bZkN98wo3/mO26/DO6tnItS8Oi+sf83vwtEcdjne7nIEtE3qbgd7+1gJN+GbkwrNN17YuzEohbP2bdYk6OLXEWXMhWstFs4URBKWaARZudFyf1yqrtB32dErvtQGVUu2w89sXp3sczZew4EL0VncpWjfUjcaSqho17Dod1jZXyPu3YWeHmyuvojYHdjstY2U7RBXMVL8t+pcumnhE/5kzy0zfmM+qMzknn8978LZzTq03cdKkOhQkuAn3HaR3uiDHzye3UVycOVnpb527YE1PCfh+rqeUPH3rzOnAa/MuSgXbfaZ+gZ4ImcdJVlQquxewnyzIS2Mc78TwVxsdYuDUZpXbqg7Ed9d3w8vR1ntI7tZj/5ZBHPlgyUmlmylfSEfjJDwquxZzrVNfUxvVMsBOvMsYOtpTZinzQhxWLN+7JTXtoPLJxqau8J033XLeYY7AwjgtYMu4+iXL/e4sZ8MjHntYfTCYyXCqucPuBypStHO0Ub3rzviOs2n6QJyYuz/iHRpNZkn382pSRBVzx9BcxZ76VR5ndlkpCEeu8LgybKKnQY8996k8IUSeimSiue2Emfw2uZrc5wzHZBQOyAf2N8c5UlwH2o5Gue64VcxyOxIj3+/mq5B5yQpj65HeTVsROFwMvrUY3k1O88tIX6Z8YEJpqm/vquB6tl70Tb2WgbEEr5gLEy1f/2U9Xx0+URcRrCCsM00Zoaa5cRreY8xc9+BeHbKv8fgyGebmk+Rv9n2qdSty0iM95bHLK5dDkJ+kaVyrIFvM/MtCVzid++0H64/9qnMiyVkMBoG3MKeTXUWIFO6GrfiSpHLxLlmiDevlkWw7x8TL/45MUAve/tyjhc7VXhiZl5KvLmFKqzutCo4nGqzM2ZFqEuGjFXIC8PD12TONcZvPe/JxMoskOtCkjDew8eJQnJi6PObU1H1uXD7/v3pSTSygFHVqVxE2j0STKpr0x1472jYJWzGP+s5C/BlczfU2s5Qk1ucK2A5U8MyW33Ps0ucX7C6PHlfGTglbMx2qM2XOx1vmaVq6Vdq5wtgs3uDyY8KcpAApaMYeIFQzm//6zMI2SaFKNNmVocoGCVsz5EC9Bo9HkH64Us4iMEJEVIlIuImMcjpeIyFjz+EwRKTP3l4rIFBGpEJGnLembish4EVkuIktE5DG/LsgLn63cCWhfZY1Gk13EVcwiUgQ8A1wK9AOuFZF+tmQ3AXuVUr2AJ4HHzf2VwC+Bexyy/r1Sqi9wJnCOiFya2CUkxnV/n1H/Q2vmvEd3jjS5hJsW8yCgXCm1Ril1DHgDGGVLMwp42dx+GxguIqKUOqSUmoqhoOtQSh1WSk0xt48BXwJdkrgOz0xbXT+opwOOazSabMJNEKPOwEbL703A4GhplFLVIrIfKAXixsUUkdbAV4GnohwfDYwGaN++PcFg0IXI9XRrrlhfEbu59Iu35vL4eU095avJLXZVGDMC/zd5aoYl0eQ6Vh1UUVHhWSe5IaPR5USkGHgd+LNSyjEAg1LqeeB5gIEDB6pAIOCpjKLpHwCxg8pvP6wIBAIwMTWramiyh+J2PYElmRZDk8NYdVAwGMSrTnKDG1PGZqCr5XcXc59jGlPZtgLcOAA/D6xSSv3JRVqNRqMpCNwo5tlAbxHpLiKNgGuAcbY044AbzO2rgMkqzlxmEXkEQ4Hf4U1kb+gxH42VB/6rW8ua7CeuKcO0Gd8GTAKKgJeUUktE5CFgjlJqHPAi8IqIlAN7MJQ3ACKyDmgJNBKRK4GLgQPAfcBy4EvTn/hppdQLfl6cUb7fOWo0Gk1qcWVjVkpNACbY9j1g2a4Ero5yblmUbLXK1Gg0GgcKeuaflT98mPjiphqNRuMnea+Y3TbL/zK5PKVyaDQajVvyXjFrNBpNrpH3ivmElnl/iRqNJs/Ie611VZ9GmRZBo/GNFo2LmXjHsEyLoUkxea+Yi7TvhyaPeOTKU+jboWWmxdCkmLxXzNqPWZNPPDp+WaZF0KSB/FfMmRZAo/GRHQePZloETRrQilmjKUC+d05ZpkXQxCD/FbPWzJo84qJ+7TMtgiYN5L1i1mjyiTbNtZdRIZD3ilk3mDX5RG3s0OKaPCH/FbO2ZWjyCD+WQfvamZ19kESTSvJeMaeTFo0zuiCMpgCo9WF5yh8HeiK6L5nVaMXsIz8Y1iPTImjyHKWXdC8ItGL2keYlusWsSS1+LejeQDeYsxqtmH2kuTZlaDzSvKSYzq2buE7vh40ZtBtptlMQivn+kSdlWgSNxhGlFJPuPI9ZvxjOV/q2i5veDxuzJvspCMXcoVXj9BSkXxqNR07q2JLmJcW0a9mYv393YNz0frSYReDr/bsknY8mdRSEYtYj0NEpbZa/Exb++M3TMy1CXEoa1r+CRS4Mv3EWn3dFAxFO6qgj1GUzrhSziIwQkRUiUi4iYxyOl4jIWPP4TBEpM/eXisgUEakQkadt5wwQkUXmOX+WFDocp8uelosj5vdfnr9mnnN7tcm0CGF83Qf/YT8mmHRv0wyA0edpL6JsJa5iFpEi4BngUqAfcK2I9LMluwnYq5TqBTwJPG7urwR+CdzjkPXfgB8Avc2/EYlcgCY5/Brl18TnxA4tIvZ5vf/NfPD8CbWBhvYoTTqvQmT/4aqUl+GmxTwIKFdKrVFKHQPeAEbZ0owCXja33waGi4gopQ4ppaZiKOg6RKQj0FIpNUMZfbN/AVcmcyGxOKdnGzq3bsJ1g09IVRFAbiq5fB5MKikuyrQIYTjd6m6lTT3l8c2B/tmGh/Vuw3eGdPMtv0Lh9Ic+THkZbj6/nYGNlt+bgMHR0iilqkVkP1AK7IqR5yZbno79PBEZDYwGaN++PcFg0IXI9VRUVDBv1hc8OqQBwY3bPJ3rleUrVqQ0/1SwbFn+Bl7/cubUTItQx5ntilizenXYvjv6l9Cv1W5PdXp7+UKCG5KzzVnLG94aXrEc+/lZjZm/o5pJ66uTKiPfCd3DiooKzzrJDVnveKuUeh54HmDgwIEqEAh4Oj8YDBI6Z+usDbBkkc8S1nPiiSemNP9U0OfEE2FxcjLPum84gx79xCeJ/OOCCy6ASeMzLQYA3bt0oEf7FrByed2+O755YWTCibHlHXlhwBgkjJPuyjM68d78LY7HIt4hS14/+sZwAG7995eMX7g1ZhmFTOgeWvWLn7gxZWwGulp+dzH3OaYRkWKgFbA7Tp7WPplTnjlHLpoy/JBZe724QKWnfrwxeggAZyc58FlSVBAOW1mLm7s/G+gtIt1FpBFwDTDOlmYccIO5fRUwWcXw61FKbQUOiMgQ0xvju8B/PUvvkXSqj2sHdaVDyzT5TyeBHzZmPYssPgro6zD455XQrX5o1MmOx4f0KOXTnwW4ekBytujiHFzFeFDZ8ZkWwTfiKmalVDVwGzAJWAa8qZRaIiIPicgVZrIXgVIRKQfuAupc6kRkHfBH4EYR2WTx6Pgx8AJQDqwGPvDnkqKTagVidZf7St/2zPjF8NQW6APJTlg4p1epbi+74JxebbjAxcw+t/Rq2zzqsW6lzZIOd3vvpbnnRunGDzxXcGVjVkpNACbY9j1g2a4Ero5yblmU/XOAU9wK6gep6nKXNmvE7kPHwvYV50glcerYtGtRErHo54d3nsfFT34Wkfa1m4ewx3btmkiuSrIFm26Oy8GJR/mkmAvLkJSi59blOCMITZvmJXX7cqWSuDVl9GkfvRueG1eaXq45q2v8RC549Gun8N6t59T9rmsI5+BN/8PVqZ2JmSvvnBuy3isjFxh9Xk9Kihsw/KT6rmquVBInU4ZX44a2MUfi1z25fnDm/Iz7n9CaLzfs8y2Pc3undibmZad24NOVO1NaRrooqBZzqvRHA4EL+7UPs+tlg2J+5aZBcdNceJJedTkV3HlRHy47tUOmxUgKv6Mk+DFrMRaNivNHneXPlbggnev/OSnm9i1LHFKmjmG928Y8PrRHKV2P9zbzzIlkbfcn+CBDttGuRWP+ev0A3/MN1WGne+73Ctp+BUwCGHlaR08LSbx9y1Ceua5/0uX7QZ/20QdaU0VhKeYU5XvoWE3Evga2j0DfDi0obpBdtzuaS5Tn9zHJGzv2h0Mc9994dlnUc97/ybnJFZoh/HCZg0hTyRPnNeHju873JW8/CcnZsnFDT+cNLDuekad19FZWit7wHwd6pSTfWGSXpkgxqWowL9myP2JfyCtjwu3DUlNoFtDSXLEl2fvasZXzCh6xQpKe0rlVcoVmiCvO6JSSfNs1bUDrpsm1mG8+t3vY71DrPAuscq5IRXTHwIltMzKGUlCKOVUcrY6MxehkynD7gH99hfPkgfThroJ/cncASL+DQDrWVjzVVPwnd/I3brG9J5Uoqbjn90VZ6eeN0UNZ/ZvLEsqzfEdFMiLVcVxTby1uv/DreXkuNyOlZohU3ePNe49E7CszY94mwg0xuvBeuefiPlGPRbO5uzVltG1REjOfVFGThpB4I04xBu7O7xPbTu+VeK3PWb8YTtfj3a8BGIvB3d3NhLv9K70Y1rtNxHN85MpTOLdXG07r0irhwey9dSEyk3tm916WmQkv7Vqkd1woRGEpZhftjG8P8R4a1MnlrFmjyJCTmfj43vaV3gmdd3E/994a1svyGsYyFh8t2+64368FSWMRGvjy+5nFa4G1a9mY8+IM2rrF7Sold118Iq/cZA8YaZz/6s2DadwwvC6/fctQ1zKEfPvTESfk0NHIsZ5k+e7QsozEwCksxeziJSsr9d7SdXpwbluRb3mo5H5z2SnR3bmeuuZM1/lYL7V3O/9GsBduirTdQ7oUs/Hf7wElN/XCzdW5ySe4YoeLnLwzoNtxrtOeYLb+E31kF54UPo29ccPoKmv/EaN1fuYJrfn4rvMSK9BGrVLaxpwNJNItd3uK/SW/5+I+nN6ltefy/OJbPs1Os16Xk709Fl5e8hDpMGV866yunNSxJdcn0IOKhRuLQBsX06Hd1Ll1uw+7kMg7Tu/I/SNPYu79kWFMS0MtZvNzc3yUazurzLkeXHGGEaa9n0Pr/+ZzuzP+9nrvHKu5pVc7f7xflDLMWtcO8uddcUtBKWY3SjeRj2PbBO1QNbWZnTUXrRWjSFyuz1dFWxvBmVZNvA/qpGPVlXYtG/PBT4dF9RhJFDeDSYmanzLFzed25+ZhPeqUcIjnvjOgLspdB/M+RoshE02RXnF6J9Y9NrLO395aZ++/vB8nd6r3zgm55PnZoapVipLiIn779dP8y9QFBaWYG7mIMZuQQnJZEex51yqVsZAHd1/UhwZRXhL7xIL+J8Ru1ef6lOxP7g73/413vVDvKugVN/cq12awRbumS07uwEX92vPMdf35yVcMX+ArTnd2F7zzwtgfo1AZTko3NAHEy/jkg1+1L1vqTE2GgqznVg1Ikos8DGh5IZbN8wRzMOwnDq0gN7bSX7msQF75yfBIec7pVb84Z7rqox+zy5Klpy2Epr1F3q20aYRP9cIHL3Ec4LXz6NdOCVNGoV7bwARMOFa8fgtTGd1ueIxp/SLCyNM60tBsFEX76LSzxC4fcXLk2Eemvv2Zqp8FpZiLGkhUW1aIRCpArK5185Ji1j02kpGndYzIu6ZWxTWvXHF6J24YWh/IZrKtdecn7VsYL4ebqniiJdpcMi3mbgkMtqabT392AXN/eVHd7+FmXGU3ZonrB3fjz9fWD6QGTPe7+y9PzQc3Gn6NJ9hZ99hIhnhYbdvpnvUrNdRQ6L46zfgLvSduJpEkOnjq5JGVqcWKC0oxQ/xR9liKct1jIx33u/USsOdd48KUoWzn9bC07lo2LuYfN57lquxYhDwpol2HvXLePrw3E++on9Fovac92zajW0t31eqJb5zGvZf19SgtXBrDm8QP4j3NF817nsgHqevxTVn32EjO6JrcoO/k5d48Ls4qO56pP7+A+Q9cFD9xCrGbGz79WYA7BxgNgsYxeiCxbnWdB42H53G6w/2/3aFXqyeYZAmJPIdEezu1tSqqndeat707FWpBt2leErYqxjf6J9ZdXWXOznrfsvimtWVi73aX7zgY9rGw3rPTu7Tmjv7uBkO/eVZXSoqNl9FLnAe/J30kivUexJrIkyh3X1SfZ6dWjcOWKqs46n0V6y7HNU162nay2Bsn3Uqb0bBBaOq38d+pgVB/LEbeIfXt4oV0+jC2sy0Fd++lfV2NN6QCrZh9wOq+Ne62c3ggSjc10pQRP28nr4XvRpkZuGTL/qSmc1eb16FUuOvR9UPCYwKH/EVDWK9LAcc1bkDn1rG9GezKtVe75vTt0CKqO5WVWK/d2T2du9VeIoS5XX3Geh/8HrBb99jIsHGAafcOD1uqLFfHW2O1QBvE0KsNzYBbybhK/tKj+eiH5/dM+6zWEIWnmOPc58RszPWV5bQurfm+LRiMm/PsXHhSe0aUNaRRcQPXlaNXu+a+TecOtWTB6YMSLreTfKPiBOu5w2EUfuId53HbBc6RvM48oXXdTLZYDaJ//8A5Up2XiSI/Or+n67Qh0m2L9KIwmjSMP0iZLtrFCH3b3myxOsVtLjYHD63jLRFEuSVPXHUaz357ADfZ3suvRvEQAfiKj+szJkLBKea41TlOhe/RNnKwyvVLacs6VsvshRsGck1fo/UYbWTYvtevVbnt5dnLcXO9sUI2fmdIN848wXkQNloo0nd/fE5d9zORmX9Oj7V104aOL3oTF94WEO5mlwXOJSnn+sEncP3g5CbcfGtgV5665gzHY3df3IffX316xGy/EGt+cxm/HhW5TOjjV53GoO7H08OMT2N/FN8c2LUu9omVv1x7JvMfuIgrz+jEl+bgbqjHmemIeq4Us4iMEJEVIlIuImMcjpeIyFjz+EwRKbMcu9fcv0JELrHsv1NElojIYhF5XUT80SpxOLdX7OVt4j2PyWZENSuuB//M/yHXq/NPTMxWGsrHrkD96nW1ihPJy16utRKHjp3cqRUrHhnB89+JDBYfyzc0VrCcuq5uTOnCCXWBnWI7jzy1o+OLHutxWnsCVje7bfsjA1mlEqtJINot+9qZxqy5RGZXOvHo107l0a+dmlQeDRoIo8zZfHZKiou4akCXqL2BaOMx/U84jjd/OLTOJc8LrZs24k/XnFlnQuvUOvoU8nSu9hP3SkSkCHgGuBToB1wrInZjzU3AXqVUL+BJ4HHz3H7ANcDJwAjgryJSJCKdgduBgUqpU4AiM13KufWCXnz2swt8zdOrV8ZfrjuTHwV6ck5Pd2ugDbXZTUMDP35PuW3SsIiHR53Mv28ONweU2QIT2S/X+iJZD5UUF3Gxg09qTU30+xWrFxEyZXhZ8aStORvNab25aM8tmkvWusdGRo0hMmvdXtcy+YFVd0VTZENNN7YOrdLS5vHEx3edz/R7v5JpMSKoa/Q4HGuR4KSiRHDziRkElCul1iiljgFvAKNsaUYBL5vbbwPDxagto4A3lFJHlVJrgXIzPzAWgm0iIsVAU2BLcpfijgYNpG7ShxOJtDrdmjJCOqe0WQk/H9E3rAXQI0aY0NAK1SEFuXGPt9bZf350dsyJKiEbZNNGRXxnaFnEclP2Fz/WAN3WfZVx5amOccPskcysXD/4BN7/ybmuvDJC8Xvr/F8diqyNMviaiL043RMRrIOr8apsOnvld13kzjulV7vmvk93D5GqR3HANuidStwo5s7ARsvvTeY+xzRKqWpgP1Aa7Vyl1Gbg98AGYCuwXyn1YSIX4DeJRBNz+1JGcweadd9w3rvtHKdTDJlcfi2iiTGg23F875z6gY8nvxW+jPzPLjkRcD8zMtbI+uGq+G5cNdE0Ika3NMSQHkY84ZD5SUTCVi4ZFmXV5WUPjWD6vcMj9r9uGxg8tYvzKiiJKNkqNy42PjK4R32s5WyaEn+7w4zSdJHq+xDPtdVP0tc2tyAix2G0prsD+4C3ROTbSqlXHdKOBkYDtG/fnmAw6KmsiooKT+esXLkikDVU6QAAEHVJREFU6rFQPu2bCtsP17+8u/fscVXGoUNGS3fW7NlsbxneMrQq61BeIdlrahUD2hdxeY9agsEgy7dXR6QF2LJ5E8HgDsdjVo7bX04wWF73e8NGoyWwZetWgsE9EelD+RxXIuw9qiip3B0171bqMBUVVTHvx5Zt26Me31tZr+B6llQwAyg5ts8x/d49ka1ze7rKSiPNjBkzaNu0vh3y23Ob0OHIGoLBtRF5LFi4ELZ6ezX2HQw3K3mtp17ZcKA+9nBtrXKs58s3Gc9127ZtBIOpMbXEuk6398DrOxot/7X7jXty4ODBsGNOeUcrb/EO493atTuyju/ZXV/f7O+o37ipfZsB63zOLuY+pzSbTNNEK2B3jHMvBNYqpXYCiMg7wNlAhGJWSj0PPA8wcOBAFQgEXIhcTzAYxPGcieMd05944omwZJHjsVA+TWZPgcP1L2KrVscRCDi7aVm5r802bnl1Lt+45PyI5ZFqaxVMmhBWjlX24RZzXJ99R/jLvMn1ac1r+erZpxI4tWPd74jrjrJ/66wNsGQRHTt0JBA4LWr6y/ct5pUZ6xlwSh8CQ8vC8mgz9SN2VRzjl98cyrblX4aXYbvXpW3aEgg4ryC98+BRCH4MQO9evWDZUrp07kwgEDlI9+LqmbA7PJqd/dqazJwMlUcYMmSIYaIxZbn2cpt90yLjqaeeSqCvy4Ee87ySkhKorH9xvdZTryzdcgCmfQ4YLbnmzZtFlLl99gZYvIgOHToQCJzukEsSRKtj8Y45EPUd9Vj28Zv2wfQvaNGiOYHAMJ5ru403Zm0gEBgU99w6VuyAL2fToW0bAoGBYYfe2vwlbN8adr5n2V3iRjHPBnqLSHcMpXoNcJ0tzTjgBmA6cBUwWSmlRGQc8G8R+SPQCegNzAJqgSEi0hQ4AgwH5vhwPUnjprNiNy2c1tXdwqAjTukQdVq3l25YyHMhtOxNv44tWbr1QIRt2C1+dNBCLmZufGZjDUY59Rb9MBl6sU6cVeZuSSYrmYqpAG7CDKRJkCzjkpM7cIlt8Hn0eT1irrIzrHdbbjm/JzcPi5yLkOjyWokQVzErpapF5DZgEob3xEtKqSUi8hAwRyk1DngReEVEyoE9mB4WZro3gaVANXCrUqoGmCkibwNfmvvnYbaK08V3h3bjX9PXR+xPpBKf2TV5d6REZhiFdEGskIhWnvjGaRyLYQtNZpXhW87vyX3vLqZN8xLsxoHffO1UerVrznOfruaT5TvqvAWcCJ/qnXhck/o0xn+31zawfREtGnuPER1rQDMVhF16ASpep3gpbsaHfhFn7cCiBsKYS53jt2SVYgZQSk0AJtj2PWDZrgSujnLuo8CjDvt/BfzKi7B+EusWD+/bjmG92/Dg/5YCxgOxL+1uxcv6eH5Q78ds/rYpn2e/3d9RaX0zSoQxt9+EOy/qw8HKKscQktcP7sb1g51nZV1nTkp44fM1QGz3Qief6Hg0aVjEkSrn9d68DubedGpiix6kY7krK4eP1Y8zFJpejtbrTDWXnNyBd+fZrbipISODf9lArNZWKHpYSDEvfvCSsNlgQ3qUsnbXobrf6RytBSxvorlgqO3VHHFK9Fl3sbDrln987yymldfbcI9vZjjjJ0qoxRHLgSGRe/nXb/fne/+YHTONW73ZpDixZ1mdZq+Mrfvr7dnp9K/NZpLp8bmhtHn6AkAV3JTsELd9xTkmgxP2Kbq/vuJknv12f6B+FeB0Ei3SVqKNtmitygtObMd9I/2LGxxSurFm/jXwYMpwQ31vIrWkYx1CK9Zb6LQIQ6p59tv9owbryle6JTiGkwgF+6kNKdROrRqzxdL6sFb4aF2mRsUNGGYuMZ9MNLdEsU/JTmSqshOpVi1FdZM94psyYq2GnAip7tNkagkiMO/VsfSWmWivLJX4vaK5naYOwZVSRcEqZjCC0JQ2a8QZD31Ut8/t69XMXJkkE9Sv5mAQmonnNlxlZIbGv1TrlpB4sVqXTr2BaHKd0aUVn63cWbfyihP2c68d1JXKKv/NDjHmzKQE62X169iK3eVRk2p8Ip0Gy4JWzPa13nIF++DfH795Bu8v3MLJnSKXePeUX4rbzCGTUCwLhdQLE9ej4qcX9mHEKR3pF+O6Q+eG8krVasdV6dbMFk7t0oqgg2I+v087Ggh8Z0hZ2mXKR9LpdljQitmJXBjhDrUqQ4NpxzVrxHdsEz4SIdVdwTGXnkTLJg25/LTocXBD11ajVF3cjEZFzr7RRQ0kplIGi+dKiq9NKcMd8f/+szCl5YQ408XSVB1aNWbNbzPTq8sE3doYNuBbEoin7YZU1yErWjHb2Hs4fYFKEqVlk2Juu6AXV8QJRp9ttGrSkHsvjeNHaokn8vUzO7Np7xF+eF6PhMs8p2cbxs7ZSPMUey4M7n583QSfQd29T1DxSolpg2+TRk+BbKdl44YpNS+GWszpaDkXrFdGNP5u+tpmMyLCPZecWBd1Lp+wTpYpLmrAXRf1cVzRwi0PX3kKU+4JuFqyKhmKGki92SSlJRmEehNn+DC5SeONdDxf3WK2kc7ZPZpI/F5jrVFxA7rHCKnqFzW1qm5ELh0tqpaNG/L+T851XFFHk1rSsQ6gVsw2GhawYk714J9bbjm/p+NSQNmMqtfLabNFWkOgZhut46yCk4vUmTLSUJZWzBgrYyzbegCoX/SxEEnn4EYsosUqyGZqlYqYIl+oTL77fFo3zV/bdzqer1bMwBs/GMLpDxlx+hP2BfaBd358No2LM7eicba0mHMRa6yMQlfMPXLUDTUe9R9ebcpIC9bFR9dYYmCkm/5RVo5ONemoaKlmzv0Xsj+NS//YqVUwsOw4hvYo5YHL0z8bVJN6SoobMLj78YxOwkvILVoxa/KCNs1Lko5bckbX1kBiyr1H22Y0bljE66PjL5igyU1EhLE/HJqWsrRithFa7l5TWKz+zWUI8NlnnyZ0vn1FGo0mGQp3pCsKmTInaDJLUQNJKOTo/SONCTMZjGGkyUO0YrbRsIC9MjTeCdUX7f+u8RPd/7JRUqwVs8Y9Vw/swuLN+7njwvTHRNbkL1oLmZzU0QiGc8PZZZkVJAOEGnsN8sA7I900bVTM764+Pa/9djXpR7eYTZqGVnlulDk/4kwx8rSOzNuwjzsv6pNpUTQaDS5bzCIyQkRWiEi5iIxxOF4iImPN4zNFpMxy7F5z/woRucSyv7WIvC0iy0VkmYikxw8lCqFVNQqxzVhSXMTDV56S8kA/Go3GHXEVs4gUAc8AlwL9gGtFxL7Y103AXqVUL+BJ4HHz3H7ANcDJwAjgr2Z+AE8BE5VSfYHTgWXJX07i1MU5KETNrNFosgo3LeZBQLlSao1S6hjwBjDKlmYU8LK5/TYwXIzpZKOAN5RSR5VSa4FyYJCItALOA14EUEodU0rtS/5y/EBrZo1Gk1ncKObOwEbL703mPsc0SqlqYD9QGuPc7sBO4B8iMk9EXhCRjMYv1H6oGo0mW8jU4F8x0B/4iVJqpog8BYwBfmlPKCKjgdEA7du3JxgMeiqooqLC1TmVh44AsGDelxxcmx0DgG5lzzZyVW7IXdlzVW7QsjuilIr5BwwFJll+3wvca0szCRhqbhcDuzBsAmFpQ+mADsA6y/5hwPh4sgwYMEB5ZcqUKa7Sbd13RP1h0nJVW1vruYxU4Vb2bCNX5VYqd2XPVbmVKhzZgTkqjo4L/bkxZcwGeotIdxFphDGYN86WZhxwg7l9FTDZFGQccI3ptdEd6A3MUkptAzaKyInmOcOBpS6/JSmhQ6vG3HXxiXkRaU2j0eQ2cU0ZSqlqEbkNo7VbBLyklFoiIg9hfAHGYQzivSIi5cAeDOWNme5NDKVbDdyqlKoxs/4J8Jqp7NcA3/P52jQajSYncWVjVkpNACbY9j1g2a4Ero5y7qPAow775wMDvQir0Wg0hYCekq3RaDRZhlbMGo1Gk2VoxazRaDRZhlbMGo1Gk2VoxazRaDRZhlbMGo1Gk2WIyqEgESKyE1jv8bQ2GDMRc5FclT1X5YbclT1X5YbCkb2bUqqtm4Q5pZgTQUTmKKVy0l86V2XPVbkhd2XPVblBy+6ENmVoNBpNlqEVs0aj0WQZhaCYn8+0AEmQq7LnqtyQu7LnqtygZY8g723MGo1Gk2sUQotZo9FocgqtmDUajSbLyGvFLCIjRGSFiJSLyJgMyfCSiOwQkcWWfceLyEcissr8f5y5X0Tkz6a8C0Wkv+WcG8z0q0TkBsv+ASKyyDznz+JTpH8R6SoiU0RkqYgsEZGf5pDsjUVklogsMGX/tbm/u4jMNMsba8YCx1zIYay5f6aIlFnyutfcv0JELrHsT1ndEpEicy3M93NM7nXm85wvInPMfVlfX8y8W4vI2yKyXESWicjQjMrudqmTXPvDCOq/GugBNAIWAP0yIMd5GOsbLrbsewIYY26PAR43ty8DPsBYlmsIMNPcfzzGYgLHA8eZ28eZx2aZacU891Kf5O4I9De3WwArgX45IrsAzc3thsBMs5w3gWvM/c8CPzK3fww8a25fA4w1t/uZ9aYEYwHh1Wa9SmndAu4C/g28b/7OFbnXAW1s+7K+vph5vwzcbG43AlpnUva0Kql0/uFircI0ylJGuGJeAXQ0tzsCK8zt54Br7emAa4HnLPufM/d1BJZb9oel8/ka/gtclGuyA02BL4HBGDO0iu31A+9rVqasbgFdgE+ArwDvm3JkvdxmfuuIVMxZX1+AVsBaTGeIbJA9n00ZnYGNlt+bzH3ZQHul1FZzexvQ3tyOJnOs/Zsc9vuK2UU+E6PlmROym+aA+cAO4COMluI+pVS1Q3l1MprH9wOlCVyTH/wJ+D+g1vxdmiNyAyjgQxGZK8bq9pAb9aU7sBP4h2lCekFEmmVS9nxWzDmBMj6hWeuzKCLNgf8AdyilDliPZbPsSqkapdQZGC3QQUDfDIsUFxG5HNihlJqbaVkS5FylVH/gUuBWETnPejCL60sxhrnxb0qpM4FDGKaLOtItez4r5s1AV8vvLua+bGC7iHQEMP/vMPdHkznW/i4O+31BRBpiKOXXlFLv5JLsIZRS+4ApGN341iISWufSWl6djObxVsDuOLKnom6dA1whIuuANzDMGU/lgNwAKKU2m/93AO9ifBBzob5sAjYppWaav9/GUNSZk90v+1K2/WF8BddgdFNCAx0nZ0iWMsJtzL8jfFDhCXN7JOGDCrPM/cdj2MCOM//WAsebx+yDCpf5JLMA/wL+ZNufC7K3BVqb202Az4HLgbcIH0T7sbl9K+GDaG+a2ycTPoi2BmMALeV1CwhQP/iX9XIDzYAWlu1pwIhcqC9m3p8DJ5rbD5pyZ0z2tCupdP5hjJ6uxLAv3pchGV4HtgJVGF/mmzDsgJ8Aq4CPLQ9PgGdMeRcBAy35fB8oN/++Z9k/EFhsnvM0tgGMJOQ+F6PrthCYb/5dliOynwbMM2VfDDxg7u9hviDlGMquxNzf2Pxdbh7vYcnrPlO+FVhG0lNdtwhXzFkvtynjAvNvSSjvXKgvZt5nAHPMOvMehmLNmOx6SrZGo9FkGflsY9ZoNJqcRCtmjUajyTK0YtZoNJosQytmjUajyTK0YtZoNJosQytmjUajyTK0YtZoNJos4/8BRxFf1OkNvYAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [1:01:37<00:00, 16.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNTIia0DEzGD"
      },
      "source": [
        "###Uncomment to save weights of trained agent.\n",
        "agent.network.save_weights(weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-oXgDyyvzj6"
      },
      "source": [
        "__ How to interpret plots: __\n",
        "\n",
        "\n",
        "This aint no supervised learning so don't expect anything to improve monotonously. \n",
        "* __ TD loss __ is the MSE between agent's current Q-values and target Q-values. It may slowly increase or decrease, it's ok. The \"not ok\" behavior includes going NaN or stayng at exactly zero before agent has perfect performance.\n",
        "* __ mean reward__ is the expected sum of r(s,a) agent gets over the full game session. It will oscillate, but on average it should get higher over time (after a few thousand iterations...). \n",
        " * In basic q-learning implementation it takes 5-10k steps to \"warm up\" agent before it starts to get better.\n",
        "* __ buffer size__ - this one is simple. It should go up and cap at max size.\n",
        "* __ epsilon__ - agent's willingness to explore. If you see that agent's already at 0.01 epsilon before it's average reward is above 0 - __ it means you need to increase epsilon__. Set it back to some 0.2 - 0.5 and decrease the pace at which it goes down.\n",
        "* Also please ignore first 100-200 steps of each plot - they're just oscillations because of the way moving average works.\n",
        "\n",
        "\n",
        "__Training will take time.__ A lot of it actually. An optimistic estimate is to say it's gonna start winning (average reward > 10) after 10k steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30fxLmZSLRjI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3TUIIVYQqFu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3syfThiwLRg_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjeGe0fovzj8"
      },
      "source": [
        "### Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYcTnLI_vzj8"
      },
      "source": [
        "\n",
        "# Don't forget to reset epsilon back to previous value if you want to go on training\n",
        "agent.epsilon=0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kguY2XL9vzj-"
      },
      "source": [
        "#record session on a video\n",
        "import gym.wrappers\n",
        "#configure directory to store videos\n",
        "env_monitor = gym.wrappers.Monitor(make_env(),directory=\"videos\",force=True)\n",
        "\n",
        "### not using his weights\n",
        "#load stored weights of trained agent.\n",
        "#!wget --no-check-certificate \\\n",
        "#    https://github.com/GiannisMitr/DQN-Atari-Breakout/blob/master/dqn_model_atari_weights.h5?raw=true \\\n",
        "#    -O /tmp/dqn_model_atari_weights.h5\n",
        "#agent.network.load_weights('/tmp/dqn_model_atari_weights.h5')\n",
        "### using mine instead\n",
        "agent.network.load_weights(weights_path)\n",
        "\n",
        "###Range was set to 1.  was that one frame?\n",
        "sessions = [evaluate(env_monitor, agent, n_games=1) for _ in range(1)]\n",
        "env_monitor.close()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhBoiQV6MKFT"
      },
      "source": [
        "#Videos are saved in videos folder and can be downloaded\n",
        "env_monitor.directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze8NUT_LuPQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "9696b9df-cc75-429a-e51d-b0fd5401ba0e"
      },
      "source": [
        "#view a stored video of a trained agent\n",
        "%%HTML\n",
        "<video \"640\" height=\"480\" controls>\n",
        "  <source src=\"https://raw.githubusercontent.com/GiannisMitr/DQN-Atari-Breakout/master/trained-agent-game.mp4\" type=\"video/mp4\">\n",
        "</video>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video \"640\" height=\"480\" controls>\n",
              "  <source src=\"https://raw.githubusercontent.com/GiannisMitr/DQN-Atari-Breakout/master/trained-agent-game.mp4\" type=\"video/mp4\">\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}